{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOUKRQuEI+ffkIwSj4rwBY5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"07e5f6a95c45455497d04132049b89b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6ef9278222074d11a6d34c658138c136","IPY_MODEL_7ac9a6ed93064df9a1361e58abbc7d21","IPY_MODEL_02ccddf089e041afba8bc70382642b78"],"layout":"IPY_MODEL_603e5c683f93457c990e30beb17777e5"}},"6ef9278222074d11a6d34c658138c136":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fbba0f0aaf2417092e09c1aeeb86155","placeholder":"​","style":"IPY_MODEL_03cf7424531f4a9e8c15df29fe324f45","value":"Map: 100%"}},"7ac9a6ed93064df9a1361e58abbc7d21":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_23de80321ec44aa999196070216c40f1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d634b16e516b4198af6294e7b15e6cb5","value":1}},"02ccddf089e041afba8bc70382642b78":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_345f461579684574b3eff98afe1c80d0","placeholder":"​","style":"IPY_MODEL_8791b1a0b3054100bea2b6d27c920d7f","value":" 1/1 [00:00&lt;00:00, 15.15 examples/s]"}},"603e5c683f93457c990e30beb17777e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fbba0f0aaf2417092e09c1aeeb86155":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03cf7424531f4a9e8c15df29fe324f45":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23de80321ec44aa999196070216c40f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d634b16e516b4198af6294e7b15e6cb5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"345f461579684574b3eff98afe1c80d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8791b1a0b3054100bea2b6d27c920d7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["#### Text Summary\n","So now lets build our model for our data but here we will not create model we will just train the existing model"],"metadata":{"id":"yyEIcWAYfMoW"}},{"cell_type":"code","source":["# !pip install datasets\n","# !pip install transformers\n","# ! pip install sentencepiece\n","# !pip install evaluate rouge_score\n","# ! pip install transformers[torch]\n","import nltk\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sabd-CyJ1vZS","executionInfo":{"status":"ok","timestamp":1693661113304,"user_tz":-330,"elapsed":1290,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}},"outputId":"37e2b2d6-57a4-4147-e441-58138fdfc7be"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"aHBFpOj3d3QZ","executionInfo":{"status":"ok","timestamp":1693659907325,"user_tz":-330,"elapsed":3487,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"outputs":[],"source":["#import\n","\n","from datasets import load_dataset\n"]},{"cell_type":"markdown","source":["here we will use dataset to train a model and use it for give me summary of some test data"],"metadata":{"id":"vQDDKpC6f8Ng"}},{"cell_type":"code","source":["dataset_name ='amazon_reviews_multi'\n","language = 'en'\n","dataset = load_dataset(dataset_name, language)"],"metadata":{"id":"Lyu0LCxJfwXq","executionInfo":{"status":"ok","timestamp":1693659909333,"user_tz":-330,"elapsed":2015,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["In this dataset we have 3 sets of data train, test and validation.\n","To be more on experimental side i will use test data as training data while training and validation data as test data as data size is too big and take hours on colab"],"metadata":{"id":"VyNkLNEEgiEj"}},{"cell_type":"code","source":["dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AWHQOvVgggu-","executionInfo":{"status":"ok","timestamp":1693659909334,"user_tz":-330,"elapsed":13,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}},"outputId":"aa712f2f-2325-4af2-fc55-51d4a7b3b9cd"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n","        num_rows: 200000\n","    })\n","    validation: Dataset({\n","        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n","        num_rows: 5000\n","    })\n","    test: Dataset({\n","        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n","        num_rows: 5000\n","    })\n","})"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["Let's see what's inside the each reivew"],"metadata":{"id":"jvNbHHMvhNEp"}},{"cell_type":"code","source":["dataset['train'][10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gOxPv4UXhLBC","executionInfo":{"status":"ok","timestamp":1693659909335,"user_tz":-330,"elapsed":10,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}},"outputId":"cf41be0e-8887-4396-ca78-781661282698"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'review_id': 'en_0210507',\n"," 'product_id': 'product_en_0724267',\n"," 'reviewer_id': 'reviewer_en_0031791',\n"," 'stars': 1,\n"," 'review_body': 'I am disappointed in this purchase. I bought one of these in another color and in size XL and it fit great. This one I bought in white in XL and it fits like a Medium. I cannot wear this top and am really disappointed about that, It is advertised as XL but seriously this top would only fit someone who would be a size s/m. An XXL would have been a better choice for me because the sizing is incorrect on this product.',\n"," 'review_title': 'Not what I ordered',\n"," 'language': 'en',\n"," 'product_category': 'apparel'}"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["There are reivew_id, product_id, reviewer_id, stars, review_body, review_title, language, product_category but for our case we will use only reivew_title as summary and review_body as the text"],"metadata":{"id":"OOvtpFAyhW4p"}},{"cell_type":"markdown","source":["#### now lets look at data its optional as i am choosing the small dataset from this big data so that training and testing will be fast for me on a specific cateogory"],"metadata":{"id":"vYso_1ApiLv2"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np"],"metadata":{"id":"nI9vkJhpv8VN","executionInfo":{"status":"ok","timestamp":1693659910921,"user_tz":-330,"elapsed":4,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame(dataset['train'])"],"metadata":{"id":"4RnmWVtOhVPJ","executionInfo":{"status":"ok","timestamp":1693657349332,"user_tz":-330,"elapsed":26221,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["So maximum reviews are of home category items\n","Now we will take out least no. of counts category for our training"],"metadata":{"id":"TSaCK7vhv_kd"}},{"cell_type":"code","source":["df['product_category'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WhbqoHMyzWDt","executionInfo":{"status":"ok","timestamp":1693657349333,"user_tz":-330,"elapsed":6,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}},"outputId":"999df04b-a7f0-4e82-df0f-f3d95d62c6c3"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["home                        17679\n","apparel                     15951\n","wireless                    15717\n","other                       13418\n","beauty                      12091\n","drugstore                   11730\n","kitchen                     10382\n","toy                          8745\n","sports                       8277\n","automotive                   7506\n","lawn_and_garden              7327\n","home_improvement             7136\n","pet_products                 7082\n","digital_ebook_purchase       6749\n","pc                           6401\n","electronics                  6186\n","office_product               5521\n","shoes                        5197\n","grocery                      4730\n","book                         3756\n","baby_product                 3150\n","furniture                    2984\n","jewelry                      2747\n","camera                       2139\n","industrial_supplies          1994\n","digital_video_download       1364\n","luggage                      1328\n","musical_instruments          1102\n","video_games                   775\n","watch                         761\n","personal_care_appliances       75\n","Name: product_category, dtype: int64"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["df['product_category'].value_counts()[-1:] # see least no. of review"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IwJEr3W-v2VZ","executionInfo":{"status":"ok","timestamp":1693657349333,"user_tz":-330,"elapsed":3,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}},"outputId":"83556510-d5f6-4ece-f046-1eceae27ebe1"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["personal_care_appliances    75\n","Name: product_category, dtype: int64"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["So i will take personal care appliances for now and to train fast and lets delete what we are not using to save memory"],"metadata":{"id":"ibaDbK_CzluM"}},{"cell_type":"code","source":["del df"],"metadata":{"id":"fpAbbS3NzTlZ","executionInfo":{"status":"ok","timestamp":1693657363372,"user_tz":-330,"elapsed":507,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Create a function to get personal_care_applianaces from the dataset"],"metadata":{"id":"HL8eXT-9z2vo"}},{"cell_type":"code","source":["def filter_category(data):\n","  return (data['product_category'] == 'personal_care_appliances')"],"metadata":{"id":"IIgj93Mqz1i4","executionInfo":{"status":"ok","timestamp":1693659918965,"user_tz":-330,"elapsed":870,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["filter_data = dataset.filter(filter_category) # here filter is a function that is there on datasets to filter data and use parallel processing"],"metadata":{"id":"7CpBgdvE0HjZ","executionInfo":{"status":"ok","timestamp":1693659918967,"user_tz":-330,"elapsed":7,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["filter_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"USE9YJ_q0YSm","executionInfo":{"status":"ok","timestamp":1693659921274,"user_tz":-330,"elapsed":7,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}},"outputId":"e8cfb123-41d7-4ba8-d8bb-0974114ce07f"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n","        num_rows: 75\n","    })\n","    validation: Dataset({\n","        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n","        num_rows: 1\n","    })\n","    test: Dataset({\n","        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n","        num_rows: 2\n","    })\n","})"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["Now as you can see we have a very small data set that we will use for our case to train.\n","\n","Next we will get a Tokenizer and Model to train with pre trained"],"metadata":{"id":"FbEidjYv0cft"}},{"cell_type":"code","source":["# lets delete full dataset\n","del dataset"],"metadata":{"id":"cYEq3hT008LV","executionInfo":{"status":"ok","timestamp":1693659924509,"user_tz":-330,"elapsed":574,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer"],"metadata":{"id":"cApyr_TX0aag","executionInfo":{"status":"ok","timestamp":1693659927498,"user_tz":-330,"elapsed":2424,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["model_name = 'google/mt5-small' # he mt 5 is 5th version of mt model and small is its size\n","tokenizer = AutoTokenizer.from_pretrained(model_name) # based on name of model it gets tokenizer of it"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5inudp5y05Zg","executionInfo":{"status":"ok","timestamp":1693659930226,"user_tz":-330,"elapsed":2731,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}},"outputId":"de839543-3d8f-4768-ae4d-2b0414de586a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["Cool, now we have tokenizer to convert text to tokens or in our case reviews to tokens"],"metadata":{"id":"b0gq8qKz2My1"}},{"cell_type":"code","source":["def preprocess_function(data):\n","  \"\"\"This function is used to fix things tokenizer like max input length that can be given,\n","      maximum target length if maximum size exceed the length then truncate that data and lastly\n","      we add labels to model inputs data\n","  \"\"\"\n","  max_input_length = 512 #\n","  max_target_length = 30\n","  model_inputs = tokenizer(data['review_body'], max_length=max_input_length, truncation=True)\n","  labels = tokenizer(data['review_title'], max_length=max_target_length, truncation=True)\n","  model_inputs['labels'] = labels['input_ids']\n","  return model_inputs\n"],"metadata":{"id":"oR2PrKMF1fSI","executionInfo":{"status":"ok","timestamp":1693659930226,"user_tz":-330,"elapsed":5,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["tokenize_data = filter_data.map(preprocess_function, batched=True) # here map isfunction that on datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["07e5f6a95c45455497d04132049b89b6","6ef9278222074d11a6d34c658138c136","7ac9a6ed93064df9a1361e58abbc7d21","02ccddf089e041afba8bc70382642b78","603e5c683f93457c990e30beb17777e5","8fbba0f0aaf2417092e09c1aeeb86155","03cf7424531f4a9e8c15df29fe324f45","23de80321ec44aa999196070216c40f1","d634b16e516b4198af6294e7b15e6cb5","345f461579684574b3eff98afe1c80d0","8791b1a0b3054100bea2b6d27c920d7f"]},"id":"aYAGwUS03XLB","executionInfo":{"status":"ok","timestamp":1693659930226,"user_tz":-330,"elapsed":5,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}},"outputId":"bfadc839-5e79-48fd-9e5d-b73988575b41"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07e5f6a95c45455497d04132049b89b6"}},"metadata":{}}]},{"cell_type":"markdown","source":["Now lets built the model first and then evaluate functions to evaluate the data"],"metadata":{"id":"9xWdFzX23ulX"}},{"cell_type":"code","source":["from transformers import AutoModelForSeq2SeqLM"],"metadata":{"id":"__x9WU2R3mtF","executionInfo":{"status":"ok","timestamp":1693659930227,"user_tz":-330,"elapsed":4,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"],"metadata":{"id":"pj9vpxxl37KF","executionInfo":{"status":"ok","timestamp":1693659954874,"user_tz":-330,"elapsed":24651,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["Now this model need evaluation criteria, training arg and train and test data so lets do\n","\n","frist: evaluate function"],"metadata":{"id":"TPS44G7j9BTv"}},{"cell_type":"code","source":["import evaluate"],"metadata":{"id":"ZjzbGmRD4Akg","executionInfo":{"status":"ok","timestamp":1693659955637,"user_tz":-330,"elapsed":765,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["rouge_score = evaluate.load('rouge')"],"metadata":{"id":"qTIl1tTe80kO","executionInfo":{"status":"ok","timestamp":1693659956461,"user_tz":-330,"elapsed":825,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Now we have rouge score to evaluate and its time to make argument object\n","# for that first need to import arguments\n","from transformers import Seq2SeqTrainingArguments"],"metadata":{"id":"JmXH5NmM9iMa","executionInfo":{"status":"ok","timestamp":1693659956463,"user_tz":-330,"elapsed":12,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# now we will create some details about it\n","batch_size = 8\n","num_train_epochs = 8\n","logging_steps = len(filter_data['train']) // batch_size\n","only_model_name = model_name.split('/')[-1] # to get model name not google"],"metadata":{"id":"cUT2AZaU9_1I","executionInfo":{"status":"ok","timestamp":1693659956464,"user_tz":-330,"elapsed":12,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# here we will add arguments\n","args = Seq2SeqTrainingArguments(\n","    output_dir = '{only_model_name}-finetuned-amazon-en', # can give any name\n","    evaluation_strategy = 'epoch',\n","    learning_rate=5.6e-5,\n","    per_device_train_batch_size = batch_size,\n","    per_device_eval_batch_size= batch_size,\n","    weight_decay = 0.01,\n","    save_total_limit = 1,\n","    num_train_epochs= num_train_epochs,\n","    predict_with_generate=True,\n","    logging_steps = logging_steps\n",")"],"metadata":{"id":"IwIkye7u-nqn","executionInfo":{"status":"ok","timestamp":1693659956465,"user_tz":-330,"elapsed":12,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["Now lets create how we will calculate compute metric to know the accuracy of model"],"metadata":{"id":"SpjiIaoyALmp"}},{"cell_type":"code","source":["def compute_metrics(eval_pred):\n","  predictions, labels = eval_pred\n","  # decode the prediction\n","  decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","  # gets the labels\n","  labels = np.where(labels!= -100, labels, tokenizer.pad_token_id)\n","  # deocde the labels\n","  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","  # get prediction\n","  decoded_preds = ['\\n'.join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n","  # get labels\n","  decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n","  # calculate rouge score\n","  result = rouge_score.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","  return result"],"metadata":{"id":"lG-yeOo4_aaW","executionInfo":{"status":"ok","timestamp":1693660249374,"user_tz":-330,"elapsed":690,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["Last step before give this data to model with args and compute metrics is to get data collator"],"metadata":{"id":"zMOPKKuIBNIh"}},{"cell_type":"code","source":["from transformers import DataCollatorForSeq2Seq"],"metadata":{"id":"2WOUANChBZWP","executionInfo":{"status":"ok","timestamp":1693660336381,"user_tz":-330,"elapsed":697,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# here to data collator we need to give tokenizer and model details\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"],"metadata":{"id":"gZxBAOvLBMWh","executionInfo":{"status":"ok","timestamp":1693660429744,"user_tz":-330,"elapsed":560,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# from tokenizer_data lets remove unwanted data to save memory\n","tokenized_datasets = tokenize_data.remove_columns(\n","    filter_data['train'].column_names\n",")"],"metadata":{"id":"XrtmK7sqBHdy","executionInfo":{"status":"ok","timestamp":1693660493094,"user_tz":-330,"elapsed":834,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["tokenized_datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sr14zShgCC3f","executionInfo":{"status":"ok","timestamp":1693660501650,"user_tz":-330,"elapsed":485,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}},"outputId":"c9066032-e43b-4c3f-933a-ab4b618a7c9d"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 75\n","    })\n","    validation: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 1\n","    })\n","    test: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 2\n","    })\n","})"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["Like we had pipeline here also we have a Seq2SeqTrainer that will have args, data, data collator, tokenizers, compute_metrics and give us result"],"metadata":{"id":"AEA_5PN5CL-X"}},{"cell_type":"code","source":["from transformers import Seq2SeqTrainer\n","from nltk.tokenize import sent_tokenize # to create sentence of data"],"metadata":{"id":"D3ghzd6RCE7F","executionInfo":{"status":"ok","timestamp":1693660954785,"user_tz":-330,"elapsed":640,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["trainer = Seq2SeqTrainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_datasets['train'],\n","    eval_dataset = tokenized_datasets['validation'],\n","    data_collator = data_collator,\n","    tokenizer = tokenizer,\n","    compute_metrics=compute_metrics\n",")"],"metadata":{"id":"7N010KFyCa8o","executionInfo":{"status":"ok","timestamp":1693661118606,"user_tz":-330,"elapsed":543,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":378},"id":"lOGGlk3yCcjW","executionInfo":{"status":"ok","timestamp":1693661985058,"user_tz":-330,"elapsed":862934,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}},"outputId":"d6c61b91-7552-4701-dcaa-4fc35d38e5c7"},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [80/80 14:12, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>20.867100</td>\n","      <td>14.306795</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>22.805800</td>\n","      <td>16.217054</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>21.997500</td>\n","      <td>15.378480</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>20.580900</td>\n","      <td>14.806763</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>18.926700</td>\n","      <td>14.403424</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>20.218700</td>\n","      <td>14.803487</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>19.901300</td>\n","      <td>14.893433</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>18.977500</td>\n","      <td>15.239052</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=80, training_loss=20.290340995788576, metrics={'train_runtime': 863.2464, 'train_samples_per_second': 0.695, 'train_steps_per_second': 0.093, 'total_flos': 93201427445760.0, 'train_loss': 20.290340995788576, 'epoch': 8.0})"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["trainer.evaluate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"id":"wPdRUQo0CfPI","executionInfo":{"status":"ok","timestamp":1693662282259,"user_tz":-330,"elapsed":1318,"user":{"displayName":"shubham mandowara","userId":"01086830669491528691"}},"outputId":"fedfa7d3-22e1-48a2-a437-764d5f71780b"},"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1/1 : < :]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 15.239051818847656,\n"," 'eval_rouge1': 0.0,\n"," 'eval_rouge2': 0.0,\n"," 'eval_rougeL': 0.0,\n"," 'eval_rougeLsum': 0.0,\n"," 'eval_runtime': 0.6349,\n"," 'eval_samples_per_second': 1.575,\n"," 'eval_steps_per_second': 1.575,\n"," 'epoch': 8.0}"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["We got a good accracy on a small dataset.\n","Great!"],"metadata":{"id":"eQg8gSRzI_9m"}},{"cell_type":"code","source":[],"metadata":{"id":"lyE84pPYI3n5"},"execution_count":null,"outputs":[]}]}